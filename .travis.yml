# vim ft=yaml
# travis-ci.org definition for DataLad build
language: python

python:
  - 2.7
  - 3.5
##1  - 3.6

cache:
  - apt

env:
  global:
    # will be used in the matrix, where neither other variable is used
    - BOTO_CONFIG=/tmp/nowhere
    - DATALAD_TESTS_SSH=1
    - DATALAD_LOG_CMD_ENV=GIT_SSH_COMMAND
    - TESTS_TO_PERFORM=datalad
    - NOSE_OPTS=
    - NOSE_SELECTION="integration or usecase or slow"
    - NOSE_SELECTION_OP="not "   # so it would be "not (integration or usecase)"
    # Special settings/helper for combined coverage from special remotes execution
    - COVERAGE=coverage
    - DATALAD_DATASETS_TOPURL=http://datasets-tests.datalad.org
  matrix:
    - DATALAD_REPO_DIRECT=yes
##1    - DATALAD_REPO_VERSION=6
    - DATALAD_REPO_VERSION=5

# Disabled since old folks don't want to change workflows of submitting through central authority
#    - secure: "k2rHdTBjUU3pUUASqfRr7kHaaSmNKLLAR2f66A0fFSulih4CXxwLrR3g8/HP9m+jMve8mAYEiPSI7dT7cCm3WMA/piyLh2wKCGgzDD9oLjtvPAioR8dgLpzbgjxV/Vq6fwwPMlvbqqa+MmAImnAoSufEmI7zVQHCq11Hd5nd6Es="
#    - secure: "Az7Pzo5pSdAFTTX6XXzE4VUS3wnlIe1vi/+bfHBzDjxstDvZVkPjPzaIs6v/BLod43AYBl1v9dyJR4qnBnaVrUDLB3tC0emLhJ2qnw+8GKHSSImCwIOeZzg9QpXeVQovZUqQVQ3fg3KIWCIzhmJ59EbMQcI4krNDxk4WcXmyVfk="

matrix:
  include:
  # Additional custom ones
  - python: 3.7-dev
    # Single run for Python 3.7
    env:
    # Run all tests in a single whoop here
    # We cannot have empty -A selector, so the one which always will be fulfilled
    - NOSE_SELECTION=
    - NOSE_SELECTION_OP=not
  - python: 3.6
    # Single run for Python 3.6
    env:
    # Run all tests in a single whoop here
    # We cannot have empty -A selector, so the one which always will be fulfilled
    - NOSE_SELECTION=
    - NOSE_SELECTION_OP=not
  - python: 3.5
    # Split runs for v6 since a single one is too long now
    env:
    - DATALAD_REPO_VERSION=6
    - NOSE_SELECTION_OP=not
  - python: 3.5
    env:
    - DATALAD_REPO_VERSION=6
    - NOSE_SELECTION_OP=""
  - python: 3.5
    # Run slow etc tests under a single tricky scenario
    env:
    - TMPDIR="/var/tmp/sym link"
    - NOSE_SELECTION_OP=""
    # And the leading - in filenames for the most challenge
    - DATALAD_TESTS_OBSCURE_PREFIX=-
    - DATALAD_LOG_TRACEBACK=collide  # just a smoke test for now
  - python: 3.5
    # A run loaded with various customizations to smoke test those functionalities
    # apparently moving symlink outside has different effects on abspath
    # see  https://github.com/datalad/datalad/issues/878
    env:
    # eventually: - TMPDIR="/var/tmp/sym ссылка"
    - TMPDIR="/var/tmp/sym link"
    # and obscure the names more a bit
    - DATALAD_TESTS_OBSCURE_PREFIX=-
    # By default no logs will be output. This one is to test with log output at INFO level
    - DATALAD_LOG_LEVEL=INFO
    - DATALAD_LOG_TRACEBACK=1  # just a smoke test for now
    - DATALAD_LOG_VMEM=1
  - python: 3.5
    # By default no logs will be output. This one is to test with low level but dumped to /dev/null
    env:
    - DATALAD_LOG_LEVEL=2
    - DATALAD_LOG_TARGET=/dev/null
    - DATALAD_TESTS_PROTOCOLREMOTE=1
    - DATALAD_TESTS_DATALADREMOTE=1
    - DATALAD_LOG_CMD_CWD=1
    - DATALAD_LOG_CMD_OUTPUTS=1
    - DATALAD_LOG_CMD_ENV=1
    - DATALAD_LOG_CMD_STDIN=1
    - DATALAD_TESTS_UI_BACKEND=console
    - DATALAD_TESTS_OBSCURE_PREFIX=-
    - DATALAD_SEED=1
    - GIT_AUTHOR_DATE="Thu, 07 Apr 2005 22:13:13 +0200"
    - GIT_AUTHOR_NAME=blah
    - GIT_AUTHOR_EMAIL=committer@example.com
    - GIT_COMMITTER_DATE="Thu, 07 Apr 2005 22:13:13 +0200"
    - GIT_COMMITTER_NAME=blah
    - GIT_COMMITTER_EMAIL=committer@example.com
  - python: 3.5
    # Test some under NFS mount  (only selected sub-set)
    env:
    - TMPDIR="/tmp/nfsmount"
    - TESTS_TO_PERFORM="datalad.tests datalad.support"
  #
  # The ones to run only on weekends against master.
  # They will not contribute to coverage etc, but might lead to failed status
  #
  - python: 3.5
    # By default no logs will be output. This one is to test with log output at INFO level
    env:
    - _DL_UPSTREAM_GITPYTHON=1
    # It is not usable without setting locales env vars ATM
    # see https://github.com/datalad/datalad/issues/3159
    # - _DL_UPSTREAM_GITANNEX=1
    # Just so we test if we did not screw up running under nose without -s as well
    - NOSE_OPTS=
    - _DL_CRON=1
  # run if git-annex version in neurodebian -devel differs
  - python: 3.5
    env:
    - _DL_DEVEL_ANNEX=1
    - _DL_CRON=1
  # Run with latest git rather than the bundled one.
  - python: 3.5
    env:
    - DATALAD_USE_DEFAULT_GIT=1
    - _DL_UPSTREAM_GIT=1
    - _DL_CRON=1
  - python: 3.5
    env:
    # to test operation under root since also would consider FS "crippled" due to
    # ability to rewrite R/O files
    - NOSE_WRAPPER="sudo -E"
    # no key authentication for root:
    - DATALAD_TESTS_SSH=0
    - _DL_CRON=1
  - python: 3.5
    env:
    - DATALAD_TESTS_NONETWORK=1
    # must operate nicely with those env variables set
    - http_proxy=
    - https_proxy=
    - _DL_CRON=1
  - python: 3.5
    env:
    - PYTHONPATH=$PWD/tools/testing/bad_internals/_scrapy/
    - _DL_CRON=1
  - python: 3.5
    # Test under NFS mount  (full, only in master)
    env:
    - TMPDIR="/tmp/nfsmount"
    - _DL_CRON=1
#  - python: 3.5
#    # test whether known v6 failures still fail
#    env:
#    - DATALAD_REPO_VERSION=6
#    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
#    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
#    - DATALAD_TESTS_SSH=1
#    - _DL_CRON=1
  - python: 3.5
    # test whether known direct mode failures still fail
    env:
    - DATALAD_REPO_DIRECT=yes
    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
    - DATALAD_TESTS_SSH=1
    - _DL_CRON=1

  - python: 3.5
    # test with extension datalad-crawler
    env:
    - BUILD_DATALAD_EXTENSION=datalad-crawler
    - TESTS_TO_PERFORM=datalad_crawler
    # Use a selector that will always be true.
    - NOSE_SELECTION_OP=not
    - NOSE_SELECTION=

  - python: 3.5
    # test with extension datalad-neuroimaging
    env:
    - BUILD_DATALAD_EXTENSION=datalad-neuroimaging
    - TESTS_TO_PERFORM=datalad_neuroimaging
    # Use a selector that will always be true.
    - NOSE_SELECTION_OP=not
    - NOSE_SELECTION=

  - python: 3.5
    # test with extension datalad-container
    env:
    - BUILD_DATALAD_EXTENSION=datalad-container
    - TESTS_TO_PERFORM=datalad_container
    # Use a selector that will always be true.
    - NOSE_SELECTION_OP=not
    - NOSE_SELECTION=

# Requires current master (0.12.x) so cannot be tested against 0.11.x
#
#  - python: 3.5
#    # test with extension datalad-revolution
#    env:
#    - BUILD_DATALAD_EXTENSION=datalad-revolution
#    - DATALAD_REPO_VERSION=6
#    - TESTS_TO_PERFORM=datalad_revolution
#    # Use a selector that will always be true.
#    - NOSE_SELECTION_OP=not
#    - NOSE_SELECTION=

  allow_failures:
  # Test under NFS mount  (full, only in master)
  - python: 3.5
    env:
    - TMPDIR="/tmp/nfsmount"
    - _DL_CRON=1
#  # test whether known v6 failures still fail
#  - env:
#    - DATALAD_REPO_VERSION=6
#    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
#    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
#    - DATALAD_TESTS_SSH=1
#    - _DL_CRON=1
  # test whether known direct mode failures still fail
  - env:
    - DATALAD_REPO_DIRECT=yes
    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
    - DATALAD_TESTS_SSH=1
    - _DL_CRON=1

# Causes complete laptop or travis instance crash atm, but survives in a docker
# need to figure it out (looks like some PID explosion)
#  - python: 3.5
#    # we would need to migrate to boto3 to test it fully, but SSH should work
#    env:
#    - DATALAD_TESTS_SSH=1
#    - UNSET_S3_SECRETS=1

before_install:
  - if [ ! -z "${_DL_CRON:-}" ]; then
      if [ ! ${TRAVIS_EVENT_TYPE} = "cron" ]; then
        echo "Exiting since should only be ran on a weekly basis by cron!";
        exit 0;
      fi
    fi
  # Life was so fast that we needed a slow down
  # - sleep 60   # TEMP -- to spot diff
  # Just in case we need to check if nfs is there etc
  - sudo lsmod
  # The ultimate one-liner setup for NeuroDebian repository
  - bash <(wget -q -O- http://neuro.debian.net/_files/neurodebian-travis.sh)
  - travis_retry sudo apt-get update -qq
  - travis_retry sudo apt-get install eatmydata  # to speedup some installations
  - sudo eatmydata tools/ci/prep-travis-forssh-sudo.sh
  - tools/ci/prep-travis-forssh.sh
  # Install grunt-cli
  - eatmydata npm install grunt-cli
  # Install optionally upstream current development so we are sure that they break nothing important for us
  - if [ ! -z "${_DL_UPSTREAM_GITPYTHON:-}" ]; then pip install https://github.com/gitpython-developers/GitPython/archive/master.zip; fi
  - if [ ! -z "${_DL_UPSTREAM_GITANNEX:-}" ]; then sudo tools/ci/install-annex-snapshot.sh; sudo ln -s `find /usr/local/lib/git-annex.linux -maxdepth 1 -type f -perm /+x` /usr/local/bin/; else sudo eatmydata apt-get install git-annex-standalone ; fi
  # Install optionally -devel version of annex, and if goes wrong (we have most recent), exit right away
  - if [ ! -z "${_DL_DEVEL_ANNEX:-}" ]; then tools/ci/prep-travis-devel-annex.sh || exit 0; fi
  # Optionally install the latest Git.  Exit code 100 indicates that bundled is same as the latest.
  - if [ ! -z "${_DL_UPSTREAM_GIT:-}" ]; then sudo tools/ci/install-latest-git.sh || [ $? -eq 100 ] && exit 0; fi

install:
  # Install standalone build of git-annex for the recent enough version
  - travis_retry sudo eatmydata apt-get install zip pandoc p7zip-full
  - travis_retry sudo eatmydata apt-get install shunit2
  # for metadata support
  - travis_retry sudo eatmydata apt-get install exempi
  - git config --global user.email "test@travis.land"
  - git config --global user.name "Travis Almighty"
  - cd ..; pip install -q codecov; cd -
  - pip install -r requirements-devel.txt
  - pip install 'sphinx>=1.7.8'
  # So we could test under sudo -E with PATH pointing to installed location
  - sudo sed -i -e 's/^Defaults.*secure_path.*$//' /etc/sudoers
  # TMPDIRs
  - if [[ "${TMPDIR:-}" =~ .*/sym\ link ]]; then echo "Symlinking $TMPDIR"; ln -s /tmp "$TMPDIR"; fi
  - if [[ "${TMPDIR:-}" =~ .*/d\ i\ r ]]; then echo "mkdir $TMPDIR"; mkdir -p "$TMPDIR"; fi
  - if [[ "${TMPDIR:-}" =~ .*/nfsmount ]]; then echo "mkdir $TMPDIR"; mkdir -p "$TMPDIR" "${TMPDIR}_"; echo "/tmp/nfsmount_ localhost(rw)" | sudo bash -c 'cat - > /etc/exports'; sudo apt-get install -y nfs-kernel-server; sudo exportfs -a; sudo mount -t nfs localhost:/tmp/nfsmount_ /tmp/nfsmount; fi
  # S3
  - if [ ! -z "$UNSET_S3_SECRETS" ]; then echo "usetting"; unset DATALAD_datalad_test_s3_key_id DATALAD_datalad_test_s3_secret_id; fi
  # Install grunt to test run javascript frontend tests
  - npm install grunt
  - npm install grunt-contrib-qunit@>=3.0.1
  - if [ "${BUILD_DATALAD_EXTENSION:-}"x = "datalad-container"x ]; then travis_retry sudo eatmydata apt-get install singularity-container; fi

script:
  # Test installation system-wide
  - sudo pip install .
  - if [ ! -z "${BUILD_DATALAD_EXTENSION:-}" ]; then pip install "$BUILD_DATALAD_EXTENSION"; fi
  - mkdir -p __testhome__
  - cd __testhome__
  # Run tests
  - WRAPT_DISABLE_EXTENSIONS=1 http_proxy=
    PATH=$PWD/../tools/coverage-bin:$PATH
    $NOSE_WRAPPER `which nosetests` $NOSE_OPTS
      -A "$NOSE_SELECTION_OP($NOSE_SELECTION)"
      --with-doctest
      --with-cov --cover-package datalad
      --logging-level=INFO
      $TESTS_TO_PERFORM
  # Run doc examples if no spaces in the TMPDIR and SSH is allowed
  # Also: don't run it in extension builds
  - if [ ${DATALAD_TESTS_SSH:-0} != 1 -o -n "${BUILD_DATALAD_EXTENSION:-}" ] || echo "${TMPDIR:-}" | grep -q ' '; then
      echo "Testing examples is disabled by configuration";
    else
      $NOSE_WRAPPER ../tools/testing/run_doc_examples;
    fi
  - cd ..
  # Generate documentation and run doctests
  # but do only when we do not have obnoxious logging turned on -- something screws up sphinx on travis
  - if [ "${DATALAD_LOG_LEVEL:-}" != 2 -a -z "${BUILD_DATALAD_EXTENSION:-}" ]; then
       PYTHONPATH=$PWD $NOSE_WRAPPER make -C docs html doctest;
    fi
  # Run javascript tests
  - grunt test --verbose
  # Report WTF information using system wide installed version
  - datalad wtf

after_success:
  # submit only what we have covered in the PRs
  - if [ -z "${_DL_CRON:-}" ]; then
      cp __testhome__/.coverage .;
      coverage combine -a /tmp/.coverage-entrypoints-*;
      codecov;
    fi

# makes it only more difficult to comprehend the failing output.  Enable only when necessary
# for a particular debugging
#after_failure:
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route add -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
#  - DATALAD_LOG_LEVEL=DEBUG $NOSE_WRAPPER `which nosetests` -s -v --with-doctest --with-cov --cover-package datalad --logging-level=DEBUG
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route del -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
