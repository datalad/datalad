# vim ft=yaml
# travis-ci.org definition for DataLad build
language: python

python:
  - 2.7
  - 3.4

cache:
  - apt

env:
  global:
    # will be used in the matrix, where neither other variable is used
    - BOTO_CONFIG=/tmp/nowhere
    - DATALAD_TESTS_SSH=1
    - DATALAD_LOG_CMD_ENV=GIT_SSH_COMMAND
    - TESTS_TO_PERFORM=
    - NOSE_OPTS=-s
    - NOSE_SELECTION_OP="not "   # so it would be "not (integration or usecase)"
    # Special settings/helper for combined coverage from special remotes execution
    - COVERAGE=coverage
    - DATALAD_DATASETS_TOPURL=http://datasets-tests.datalad.org
  matrix:
    - DATALAD_REPO_DIRECT=yes
    - DATALAD_REPO_VERSION=6
    - DATALAD_REPO_VERSION=5

# Disabled since old folks don't want to change workflows of submitting through central authority
#    - secure: "k2rHdTBjUU3pUUASqfRr7kHaaSmNKLLAR2f66A0fFSulih4CXxwLrR3g8/HP9m+jMve8mAYEiPSI7dT7cCm3WMA/piyLh2wKCGgzDD9oLjtvPAioR8dgLpzbgjxV/Vq6fwwPMlvbqqa+MmAImnAoSufEmI7zVQHCq11Hd5nd6Es="
#    - secure: "Az7Pzo5pSdAFTTX6XXzE4VUS3wnlIe1vi/+bfHBzDjxstDvZVkPjPzaIs6v/BLod43AYBl1v9dyJR4qnBnaVrUDLB3tC0emLhJ2qnw+8GKHSSImCwIOeZzg9QpXeVQovZUqQVQ3fg3KIWCIzhmJ59EbMQcI4krNDxk4WcXmyVfk="

matrix:
  include:
  # Additional custom ones
  - python: 2.7
    # By default no logs will be output. This one is to test with log output at INFO level
    env:
    - _DATALAD_UPSTREAM_GITPYTHON=1
    - _DATALAD_UPSTREAM_GITANNEX=1
    - _DATALAD_NONPR_ONLY=1
    # Just so we test if we did not screw up running under nose without -s as well
    - NOSE_OPTS=
  - python: 2.7
    # Run slow etc tests under a single tricky scenario
    env:
    - NOSE_SELECTION_OP=""
    - TMPDIR="/var/tmp/sym link"
    # And the leading - in filenames for the most challenge
    - DATALAD_TESTS_OBSCURE_PREFIX=-
  - python: 3.4
    # Run slow etc tests under a single tricky scenario
    env:
    - NOSE_SELECTION_OP=""
    - TMPDIR="/var/tmp/sym link"
    # And the leading - in filenames for the most challenge
    - DATALAD_TESTS_OBSCURE_PREFIX=-
  - python: 2.7
    # By default no logs will be output. This one is to test with log output at INFO level
    env:
    - DATALAD_LOG_LEVEL=INFO
    - DATALAD_LOG_TRACEBACK=1  # just a smoke test for now
    - _DATALAD_NONPR_ONLY=1
  - python: 2.7
    # By default no logs will be output. This one is to test with low level but dumped to /dev/null
    env:
    - DATALAD_LOG_LEVEL=2
    - DATALAD_LOG_TARGET=/dev/null
    - DATALAD_LOG_TRACEBACK=collide  # just a smoke test for now
    - DATALAD_API_ALWAYSRENDER=1
    - DATALAD_TESTS_PROTOCOLREMOTE=1
    - DATALAD_TESTS_DATALADREMOTE=1
    - DATALAD_LOG_CMD_CWD=1
    - DATALAD_LOG_CMD_OUTPUTS=1
    - DATALAD_LOG_CMD_ENV=1
    - DATALAD_LOG_CMD_STDIN=1
    - DATALAD_TESTS_UI_BACKEND=console
    - DATALAD_TESTS_OBSCURE_PREFIX=-
    - DATALAD_SEED=1
    - GIT_AUTHOR_DATE="Thu, 07 Apr 2005 22:13:13 +0200"
    - GIT_AUTHOR_NAME=blah
    - GIT_AUTHOR_EMAIL=committer@example.com
    - GIT_COMMITTER_DATE="Thu, 07 Apr 2005 22:13:13 +0200"
    - GIT_COMMITTER_NAME=blah
    - GIT_COMMITTER_EMAIL=committer@example.com
  - python: 2.7
    env:
    # to test operation under root since also would consider FS "crippled" due to
    # ability to rewrite R/O files
    - NOSE_WRAPPER="sudo -E"
    # no key authentication for root:
    - DATALAD_TESTS_SSH=0
    - _DATALAD_NONPR_ONLY=1
  - python: 2.7
    env:
    - DATALAD_TESTS_NONETWORK=1
    # must operate nicely with those env variables set
    - http_proxy=
    - https_proxy=
    - _DATALAD_NONPR_ONLY=1
  - python: 2.7
    env:
    - PYTHONPATH=$PWD/tools/testing/bad_internals/_scrapy/
    - _DATALAD_NONPR_ONLY=1
  - python: 2.7
    # To make sure that operates correctly whenever dataset directories have symlinks
    # in their path.
    env:
    # Eventually we will get there, but atm causes a good number of failures
    # - TMPDIR="/tmp/sym ссылка"
    - TMPDIR="/tmp/sym link"
    - _DATALAD_NONPR_ONLY=1
  - python: 2.7
    # apparently moving symlink outside has different effects on abspath
    # see  https://github.com/datalad/datalad/issues/878
    env:
    - TMPDIR="/var/tmp/sym link"
  - python: 2.7
    # To make sure that operates correctly whenever dataset directories have symlinks
    # in their path.
    env:
    # To make orthogonal test where it is not a symlink but a dir with spaces
    - TMPDIR="/tmp/d i r"
    - _DATALAD_NONPR_ONLY=1
  - python: 2.7
    # Test under NFS mount  (only selected sub-set)
    env:
    - TMPDIR="/tmp/nfsmount"
    - TESTS_TO_PERFORM="datalad/tests datalad/support"
  - python: 2.7
    # Test under NFS mount  (full, only in master)
    env:
    - TMPDIR="/tmp/nfsmount"
    - _DATALAD_NONPR_ONLY=1
  - python: 2.7
    # test whether known v6 failures still fail
    env:
    - DATALAD_TESTS_SSH=1
    - DATALAD_REPO_VERSION=6
    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
  - python: 2.7
    # test whether known direct mode failures still fail
    env:
    - DATALAD_TESTS_SSH=1
    - DATALAD_REPO_DIRECT=yes
    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
  # run if git-annex version in neurodebian -devel differs
  - python: 2.7
    env:
    - _DATALAD_DEVEL_ANNEX=1

  allow_failures:
  # Test under NFS mount  (full, only in master)
  - python: 2.7
    env:
    - TMPDIR="/tmp/nfsmount"
    - _DATALAD_NONPR_ONLY=1
  # test whether known v6 failures still fail
  - env:
    - DATALAD_TESTS_SSH=1
    - DATALAD_REPO_VERSION=6
    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
  # test whether known direct mode failures still fail
  - env:
    - DATALAD_TESTS_SSH=1
    - DATALAD_REPO_DIRECT=yes
    - DATALAD_TESTS_KNOWNFAILURES_SKIP=no
    - DATALAD_TESTS_KNOWNFAILURES_PROBE=yes
  # run if git-annex version in neurodebian -devel differs
  - python: 2.7
    env:
    - _DATALAD_DEVEL_ANNEX=1

# Causes complete laptop or travis instance crash atm, but survives in a docker
# need to figure it out (looks like some PID explosion)
#  - python: 3.5
#    # we would need to migrate to boto3 to test it fully, but SSH should work
#    env:
#    - DATALAD_TESTS_SSH=1
#    - UNSET_S3_SECRETS=1

before_install:
  - if [ ! "${TRAVIS_PULL_REQUEST:-false}" = "false" ] && [ ! -z "${_DATALAD_NONPR_ONLY:-}" ]; then echo "Exiting early since these tests should run only in master branch"; exit 0; fi
  # Just in case we need to check if nfs is there etc
  - sudo lsmod
  # The ultimate one-liner setup for NeuroDebian repository
  - bash <(wget -q -O- http://neuro.debian.net/_files/neurodebian-travis.sh)
  - travis_retry sudo apt-get update -qq
  - travis_retry sudo apt-get install eatmydata  # to speedup some installations
  - sudo eatmydata tools/ci/prep-travis-forssh-sudo.sh
  - tools/ci/prep-travis-forssh.sh
  # Install grunt-cli
  - eatmydata npm install grunt-cli
  # Install optionally upstream current development so we are sure that they break nothing important for us
  - if [ ! -z "${_DATALAD_UPSTREAM_GITPYTHON:-}" ]; then pip install https://github.com/gitpython-developers/GitPython/archive/master.zip; fi
  - if [ ! -z "${_DATALAD_UPSTREAM_GITANNEX:-}" ]; then sudo tools/ci/install-annex-snapshot.sh; sudo ln -s `find /usr/local/lib/git-annex.linux -maxdepth 1 -type f -perm /+x` /usr/local/bin/; else sudo eatmydata apt-get install git-annex-standalone ; fi
  # Install optionally -devel version of annex, and if goes wrong (we have most recent), exit right away
  - if [ ! -z "${_DATALAD_DEVEL_ANNEX:-}" ]; then tools/ci/prep-travis-devel-annex.sh || exit 0; fi

install:
  # Install standalone build of git-annex for the recent enough version
  - travis_retry sudo eatmydata apt-get install zip pandoc
  - travis_retry sudo eatmydata apt-get install shunit2
  - git config --global user.email "test@travis.land"
  - git config --global user.name "Travis Almighty"
  - cd ..; pip install -q codecov; cd -
  - pip install -r requirements-devel.txt
  - pip install 'sphinx>=1.6.2'
  # So we could test under sudo -E with PATH pointing to installed location
  - sudo sed -i -e 's/^Defaults.*secure_path.*$//' /etc/sudoers
  # TMPDIRs
  - if [[ "${TMPDIR:-}" =~ .*/sym\ link ]]; then echo "Symlinking $TMPDIR"; ln -s /tmp "$TMPDIR"; fi
  - if [[ "${TMPDIR:-}" =~ .*/d\ i\ r ]]; then echo "mkdir $TMPDIR"; mkdir -p "$TMPDIR"; fi
  - if [[ "${TMPDIR:-}" =~ .*/nfsmount ]]; then echo "mkdir $TMPDIR"; mkdir -p "$TMPDIR" "${TMPDIR}_"; echo "/tmp/nfsmount_ localhost(rw)" | sudo bash -c 'cat - > /etc/exports'; sudo apt-get install -y nfs-kernel-server; sudo exportfs -a; sudo mount -t nfs localhost:/tmp/nfsmount_ /tmp/nfsmount; fi
  # S3
  - if [ ! -z "$UNSET_S3_SECRETS" ]; then echo "usetting"; unset DATALAD_datalad_test_s3_key_id DATALAD_datalad_test_s3_secret_id; fi
  # Install grunt to test run javascript frontend tests
  - npm install grunt
  - npm install grunt-contrib-qunit

script:
  # Verify that setup.py build doesn't puke
  - python setup.py build
  # Run tests
  - WRAPT_DISABLE_EXTENSIONS=1 PATH=$PWD/tools/coverage-bin:$PATH $NOSE_WRAPPER `which nosetests` $NOSE_OPTS -v -A "$NOSE_SELECTION_OP(integration or usecase or slow)" --with-doctest --doctest-tests --with-cov --cover-package datalad --logging-level=INFO $TESTS_TO_PERFORM
  # Generate documentation and run doctests
  # but do only when we do not have obnoxious logging turned on -- something screws up sphinx on travis
  - if [ ! "${DATALAD_LOG_LEVEL:-}" = 2 ]; then PYTHONPATH=$PWD $NOSE_WRAPPER make -C docs html doctest; fi
  # Run javascript tests
  - grunt test --verbose
  # Run doc examples if no spaces in the TMPDIR and SSH is allowed
  - if [ $DATALAD_TESTS_SSH != 1 ] || echo "${TMPDIR:-}" | grep -q ' '; then echo "skipping due spaces in $TMPDIR"; else $NOSE_WRAPPER tools/testing/run_doc_examples; fi
  # Test installation system-wide
  - sudo pip install .
  # Report WTF information using system wide installed version
  - datalad plugin wtf

after_success:
  - coverage combine -a /tmp/.coverage-entrypoints-*
  - codecov

# makes it only more difficult to comprehend the failing output.  Enable only when necessary
# for a particular debugging
#after_failure:
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route add -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
#  - DATALAD_LOG_LEVEL=DEBUG $NOSE_WRAPPER `which nosetests` -s -v --with-doctest --doctest-tests --with-cov --cover-package datalad --logging-level=DEBUG
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route del -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
