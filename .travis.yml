# vim ft=yaml
# travis-ci.org definition for DataLad build
language: python

# Do full clone (~10 extra seconds) to fetch all tags.
# Otherwise we might be missing the tags for maint PRs
# whenever those maint releases were not yet merged into master.
# TODO: specify TRAVIS_BRANCH if ever would become possible
#(support request was sent to Travis)
git:
  depth: false

services:
  - docker

python:
  - 3.7

cache:
  - apt

env:
  global:
    # will be used in the matrix, where neither other variable is used
    - BOTO_CONFIG=/tmp/nowhere
    - DATALAD_TESTS_SSH=1
    - DATALAD_LOG_ENV=GIT_SSH_COMMAND
    - TESTS_TO_PERFORM=datalad
    # Should be an array, travis breaks on it, define/adjust in the "before_install"
    #- PYTEST_OPTS=( -v )
    # Note, that there's "turtle" as well, which is always excluded from
    # running on Travis.
    - PYTEST_SELECTION="integration or usecase or slow or network"
    - PYTEST_SELECTION_OP="not "   # so it would be "not (integration or usecase)"
    - DATALAD_DATASETS_TOPURL=https://datasets-tests.datalad.org
    # How/which git-annex we install.  conda's build would be the fastest, but it must not
    # get ahead in PATH to not shadow travis' python
    - _DL_ANNEX_INSTALL_SCENARIO="miniconda --python-match minor --batch git-annex=8.20201007 -m conda"

matrix:
  include:
  # Two matrix runs for "recent python and git-annex with the recent supported by git annex
  # new version of repo"
  - python: '3.10'
    dist: focal
    env:
      - PYTEST_SELECTION=
      - PYTEST_SELECTION_OP=not
      - DATALAD_REPO_VERSION=10
      - _DL_ANNEX_INSTALL_SCENARIO="miniconda --python-match minor --batch git-annex -m conda"
  - python: '3.10'
    dist: focal
    env:
      - PYTEST_SELECTION=
      - PYTEST_SELECTION_OP=
      - DATALAD_REPO_VERSION=10
      - _DL_ANNEX_INSTALL_SCENARIO="miniconda --python-match minor --batch git-annex -m conda"

# Causes complete laptop or travis instance crash atm, but survives in a docker
# need to figure it out (looks like some PID explosion)
#  - python: 3.7
#    # we would need to migrate to boto3 to test it fully, but SSH should work
#    env:
#    - DATALAD_TESTS_SSH=1
#    - UNSET_S3_SECRETS=1

before_install:
  - PYTEST_OPTS=( -v )
  # If we requested to run only not slow (typically <10sec) tests, fail if a test
  # takes 3x more than that - it needs to get @slow or @turtle annotation
  - if echo "$PYTEST_SELECTION_OP($PYTEST_SELECTION)" | grep -q "^not.*slow"; then
      PYTEST_OPTS=( "${PYTEST_OPTS[@]}" --doctest-modules --durations=0 --durations-min=5 --fail-slow 30 );
      export DATALAD_TESTS_SETUP_TESTREPOS=1;
    fi
  # Show git describe output to ensure that we did fetch all the tags etc
  - git describe
  # Just in case we need to check if nfs is there etc
  - sudo lsmod
  # The ultimate one-liner setup for NeuroDebian repository
  - bash <(wget -q -O- http://neuro.debian.net/_files/neurodebian-travis.sh)
  - travis_retry sudo apt-get update -qq
  - travis_retry sudo apt-get install eatmydata  # to speedup some installations
  - tools/ci/prep-travis-forssh.sh
  - tools/ci/debians_disable_outdated_ssl_cert
  # Install various basic depedencies
  - travis_retry sudo eatmydata apt-get install zip pandoc p7zip-full
  # needed for tests of patool compression fall-back solution
  - travis_retry sudo eatmydata apt-get install xz-utils
  - travis_retry sudo eatmydata apt-get install shunit2
  # for metadata support
  - travis_retry sudo eatmydata apt-get install exempi
  # Configure _DL_TMPDIR before trying install git-annex -- script might use it
  - if [[ "${_DL_TMPDIR:-}" =~ .*/sym\ link ]]; then echo "Symlinking $_DL_TMPDIR"; ln -s /tmp "$_DL_TMPDIR"; fi
  - if [[ "${_DL_TMPDIR:-}" =~ .*/d\ i\ r ]]; then echo "mkdir $_DL_TMPDIR"; mkdir -p "$_DL_TMPDIR"; fi
  - if [[ "${_DL_TMPDIR:-}" =~ .*/nfsmount ]]; then echo "mkdir $_DL_TMPDIR"; mkdir -p "$_DL_TMPDIR" "${_DL_TMPDIR}_"; echo "/tmp/nfsmount_ localhost(rw)" | sudo bash -c 'cat - > /etc/exports'; sudo apt-get install -y nfs-kernel-server; sudo exportfs -a; sudo mount -t nfs localhost:/tmp/nfsmount_ /tmp/nfsmount; fi
  # Maybe build install custom git.
  - if [ ! -z "${_DL_UPSTREAM_GIT:-}" ]; then source tools/ci/install-upstream-git.sh; fi
  - if [ ! -z "${_DL_MIN_GIT:-}" ]; then tools/ci/install-minimum-git.sh; fi
  # Install git-annex
  - pip install datalad-installer
  - eval datalad-installer --sudo ok -E new.env ${_DL_ANNEX_INSTALL_SCENARIO}
  - source new.env && cat new.env >> ~/.bashrc
  - pip install --upgrade pip

install:
  - git config --global user.email "test@travis.land"
  - git config --global user.name "Travis Almighty"
  # we are pip sudo install  below and versioneer needs to run git. recent git needs to
  # be made certain it is safe to do
  - sudo git config --global --add safe.directory $PWD
  - cd ..; pip install -q codecov; cd -
  - pip install -v -r requirements-devel.txt
  # So we could test under sudo -E with PATH pointing to installed location
  - sudo sed -i -e 's/^Defaults.*secure_path.*$//' /etc/sudoers
  # git-annex workaround. TODO: remove - should not be needed
  - if [[ "${_DL_TMPDIR:-}" =~ .*/nfsmount ]]; then sudo git config --system annex.pidlock true ; fi

script:
  # Now it should be safe to point TMPDIR to a "tricky" setup just for the purpose of testing
  - if [ -n "${_DL_TMPDIR:-}" ]; then export TMPDIR="${_DL_TMPDIR}"; fi
  # Test installation for user
  - pwd
  - git "rev-parse" "--git-dir"
  - sudo pwd
  - sudo git "rev-parse" "--git-dir"
  - sudo pip install -v --user .
  # Report WTF information using system wide installed version
  - datalad wtf
  - mkdir -p __testhome__
  - cd __testhome__
  # Run tests
  #  Note: adding --log-cli-level=INFO would result in DATALAD_LOG_TARGET=/dev/null being not
  #  in effect, dumping too many logs.
  - http_proxy=
    PATH=$PWD/../tools/coverage-bin:$PATH
    $PYTEST_WRAPPER python
      -m pytest "${PYTEST_OPTS[@]}"
      -c ../tox.ini
      -m "${PYTEST_SELECTION:+$PYTEST_SELECTION_OP($PYTEST_SELECTION) and }not(turtle)"
      --doctest-modules
      --cov=datalad
      --pyargs
      -k test_setup  $TESTS_TO_PERFORM
  - cd ..

after_success:
  # cron jobs test more and then PRs will be falling behind since they would not
  # trigger some codepaths.  So submit coverage only from non-cron jobs, but report for all
  - cd __testhome__;
  - python -m coverage combine -a /tmp/.coverage-entrypoints-*;
  - python -m coverage report;
  - if [ ! ${TRAVIS_EVENT_TYPE} = "cron" ]; then
      codecov;
    fi

# makes it only more difficult to comprehend the failing output.  Enable only when necessary
# for a particular debugging
#after_failure:
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route add -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
#  - DATALAD_LOG_LEVEL=DEBUG $PYTEST_WRAPPER `which pytest` -s -v --doctest-modules --cov datalad --log-cli-level=DEBUG
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route del -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
