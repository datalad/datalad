# vim ft=yaml
# travis-ci.org definition for DataLad build
language: python
services:
  - docker

python:
  - 3.6

cache:
  - apt

env:
  global:
    # will be used in the matrix, where neither other variable is used
    - BOTO_CONFIG=/tmp/nowhere
    - DATALAD_TESTS_SSH=1
    - DATALAD_LOG_ENV=GIT_SSH_COMMAND
    - TESTS_TO_PERFORM=datalad
    # Should be an array, travis breaks on it, define/adjust in the "before_install"
    #- NOSE_OPTS=( -v )
    # Note, that there's "turtle" as well, which is always excluded from
    # running on Travis.
    - NOSE_SELECTION="integration or usecase or slow or network"
    - NOSE_SELECTION_OP="not "   # so it would be "not (integration or usecase)"
    - DATALAD_DATASETS_TOPURL=http://datasets-tests.datalad.org
    # How/which git-annex we install.  conda's build would be the fastest, but it must not
    # get ahead in PATH to not shadow travis' python
    - _DL_ANNEX_INSTALL_SCENARIO="miniconda --batch git-annex=8.20201007 -m conda"

matrix:
  include:
  - python: 3.6
    # Test under NFS mount  (full, only in master)
    env:
    - _DL_TMPDIR="/tmp/nfsmount"

before_install:
  - NOSE_OPTS=( -s -v )
  # If we requested to run only not slow (typically <10sec) tests, fail if a test
  # takes 3x more than that - it needs to get @slow or @turtle annotation
  - if echo "$NOSE_SELECTION_OP($NOSE_SELECTION)" | grep -q "^not.*slow"; then
      NOSE_OPTS=( "${NOSE_OPTS[@]}" --with-doctest --with-timer --timer-ok 5 --timer-warning 30 --timer-fail error --timer-filter warning,error );
      export DATALAD_TESTS_SETUP_TESTREPOS=1;
    fi
  # Just in case we need to check if nfs is there etc
  - sudo lsmod
  # The ultimate one-liner setup for NeuroDebian repository
  - bash <(wget -q -O- http://neuro.debian.net/_files/neurodebian-travis.sh)
  - travis_retry sudo apt-get update -qq
  - travis_retry sudo apt-get install eatmydata  # to speedup some installations
  - tools/ci/prep-travis-forssh.sh
  # Install nvm https://github.com/nvm-sh/nvm/blob/master/README.md
  - curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash
  # Use install & use node v10 as grunt-contrib-qunit uses generic try catch <https://github.com/datalad/datalad/issues/4635#issue-640604347>
  - nvm install 10 && nvm use 10
  # Echo node and npm version for debug
  - which node && node -v && which npm && npm -v
  # Install grunt-cli
  - eatmydata npm install -g grunt-cli
  # Install various basic depedencies
  - travis_retry sudo eatmydata apt-get install zip pandoc p7zip-full
  # needed for tests of patool compression fall-back solution
  - travis_retry sudo eatmydata apt-get install xz-utils
  - travis_retry sudo eatmydata apt-get install shunit2
  # for metadata support
  - travis_retry sudo eatmydata apt-get install exempi
  # Configure _DL_TMPDIR before trying install git-annex -- script might use it
  - if [[ "${_DL_TMPDIR:-}" =~ .*/sym\ link ]]; then echo "Symlinking $_DL_TMPDIR"; ln -s /tmp "$_DL_TMPDIR"; fi
  - if [[ "${_DL_TMPDIR:-}" =~ .*/d\ i\ r ]]; then echo "mkdir $_DL_TMPDIR"; mkdir -p "$_DL_TMPDIR"; fi
  - if [[ "${_DL_TMPDIR:-}" =~ .*/nfsmount ]]; then echo "mkdir $_DL_TMPDIR"; mkdir -p "$_DL_TMPDIR" "${_DL_TMPDIR}_"; echo "/tmp/nfsmount_ localhost(rw)" | sudo bash -c 'cat - > /etc/exports'; sudo apt-get install -y nfs-kernel-server; sudo exportfs -a; sudo mount -t nfs localhost:/tmp/nfsmount_ /tmp/nfsmount; fi
  # Maybe build install custom git.
  - if [ ! -z "${_DL_UPSTREAM_GIT:-}" ]; then source tools/ci/install-upstream-git.sh; fi
  - if [ ! -z "${_DL_MIN_GIT:-}" ]; then tools/ci/install-minimum-git.sh; fi
  # Install git-annex
  - pip install datalad-installer
  - eval datalad-installer --sudo ok -E new.env ${_DL_ANNEX_INSTALL_SCENARIO}
  - source new.env && cat new.env >> ~/.bashrc
  - pip install --upgrade pip

install:
  - git config --global user.email "test@travis.land"
  - git config --global user.name "Travis Almighty"
  - cd ..; pip install -q codecov; cd -
  - pip install -r requirements-devel.txt
  # So we could test under sudo -E with PATH pointing to installed location
  - sudo sed -i -e 's/^Defaults.*secure_path.*$//' /etc/sudoers
  # git-annex workaround. TODO: remove - should not be needed
  - if [[ "${_DL_TMPDIR:-}" =~ .*/nfsmount ]]; then sudo git config --system annex.pidlock true ; fi
  # Install grunt to test run javascript frontend tests
  - npm install grunt
  - npm install grunt-contrib-qunit@^4.0.0

script:
  # Now it should be safe to point TMPDIR to a "tricky" setup just for the purpose of testing
  - if [ -n "${_DL_TMPDIR:-}" ]; then export TMPDIR="${_DL_TMPDIR}"; fi
  # Test installation system-wide
  - sudo pip install .
  # Run javascript tests
  - grunt test --verbose
  # Report WTF information using system wide installed version
  - datalad wtf
  - mkdir -p __testhome__
  - cd __testhome__
  # Run tests
  - http_proxy=
    PATH=$PWD/../tools/coverage-bin:$PATH
    $NOSE_WRAPPER python -m nose "${NOSE_OPTS[@]}"
      -A "$NOSE_SELECTION_OP($NOSE_SELECTION) and not(turtle)"
      --with-doctest
      --with-cov --cover-package datalad
      --logging-level=INFO
      $TESTS_TO_PERFORM
  - cd ..

after_success:
  # cron jobs test more and then PRs will be falling behind since they would not
  # trigger some codepaths.  So submit coverage only from non-cron jobs, but report for all
  - cd __testhome__;
  - python -m coverage combine -a /tmp/.coverage-entrypoints-*;
  - python -m coverage report;
  - if [ ! ${TRAVIS_EVENT_TYPE} = "cron" ]; then
      codecov;
    fi

# makes it only more difficult to comprehend the failing output.  Enable only when necessary
# for a particular debugging
#after_failure:
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route add -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
#  - DATALAD_LOG_LEVEL=DEBUG $NOSE_WRAPPER `which nosetests` -s -v --with-doctest --with-cov --cover-package datalad --logging-level=DEBUG
#  - if [ ! -z "$DATALAD_TESTS_NONETWORK" ]; then sudo route del -net 0.0.0.0 netmask 0.0.0.0 dev lo; fi
